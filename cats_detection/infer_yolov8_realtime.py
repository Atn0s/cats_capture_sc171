# infer_yolov8_realtime.py

# å¯¼å…¥å¿…è¦çš„åº“
import os
import time
import datetime
import numpy as np
import cv2
from api_infer import *
from utils import detect_postprocess_yolov8, draw_detect_res, preprocess_img

# ==============================================================================
# --- é…ç½®åŒº ---
# ==============================================================================

# --- æ¨¡å‹ä¸SNPEé…ç½® ---
dlc_path = "/home/fibo/Cats_detection_project/cats_detection/cats_detection.dlc"
MODEL_INPUT_NAME = "images"
MODEL_OUTPUT_NAME = "output0"
MODEL_INPUT_SHAPE = (640, 640)
NUM_CLASSES = 1
CLASS_NAMES = ['cat']

# --- åå¤„ç†å‚æ•° ---
CONF_THRESHOLD = 0.6
IOU_THRESHOLD = 0.45

# --- æ–°å¢ï¼šå®æ—¶æ•æ‰ä¸è‡ªåŠ¨æ‹æ‘„é…ç½® ---
# USBæ‘„åƒå¤´IDï¼Œé€šå¸¸ä¸º 0
CAMERA_ID = 2 
# ç»“æœä¿å­˜ç›®å½•
SAVE_DIR = "/home/fibo/Cats_detection_project/cats_detection/captures"
# æŒç»­æ•è·åˆ°ç›®æ ‡çš„å¸§æ•°é˜ˆå€¼ï¼ˆé¿å…è¯¯è¯†åˆ«è§¦å‘æ‹æ‘„ï¼‰
SUSTAINED_DETECTION_FRAMES_THRESHOLD = 20 
# å®Œæˆæ‹æ‘„åçš„å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
CAPTURE_COOLDOWN_SECONDS = 80
# è§†é¢‘æ‹æ‘„æ—¶é•¿ï¼ˆç§’ï¼‰
VIDEO_DURATION_SECONDS = 20


# ==============================================================================
# --- ç¨‹åºåˆå§‹åŒ– ---
# ==============================================================================

# ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)
    print(f"Created save directory: {SAVE_DIR}")

# --- SNPE åˆå§‹åŒ– ---
print("Initializing SNPE context...")
try:
    snpe_ort = SnpeContext(dlc_path, [], Runtime.GPU, PerfProfile.BALANCED, LogLevel.INFO)
    assert snpe_ort.Initialize() == 0
    print("SNPE context initialized successfully.")
except Exception as e:
    print(f"Error initializing SNPE: {e}")
    exit()

# --- æ‘„åƒå¤´åˆå§‹åŒ– ---
print(f"Opening USB camera with ID: {CAMERA_ID}...")
cap = cv2.VideoCapture(CAMERA_ID)
if not cap.isOpened():
    print(f"Error: Could not open camera with ID {CAMERA_ID}.")
    exit()

# è·å–æ‘„åƒå¤´çš„åˆ†è¾¨ç‡å’ŒFPSç”¨äºè§†é¢‘ä¿å­˜
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30 # å¦‚æœè·å–ä¸åˆ°FPSï¼Œåˆ™é»˜è®¤ä¸º30
print(f"Camera opened successfully. Resolution: {frame_width}x{frame_height}, FPS: {fps}")


# ==============================================================================
# --- ä¸»å¾ªç¯ä¸çŠ¶æ€ç®¡ç† ---
# ==============================================================================

# çŠ¶æ€å˜é‡
detection_counter = 0           # è¿ç»­æ£€æµ‹åˆ°ç›®æ ‡çš„å¸§æ•°è®¡æ•°å™¨
last_capture_time = 0           # ä¸Šæ¬¡æ‹æ‘„ï¼ˆç…§ç‰‡æˆ–è§†é¢‘ï¼‰å®Œæˆçš„æ—¶é—´æˆ³
is_recording = False            # æ˜¯å¦æ­£åœ¨å½•åƒçš„æ ‡å¿—
video_writer = None             # VideoWriterå¯¹è±¡
video_start_time = 0            # å½“å‰è§†é¢‘å¼€å§‹å½•åˆ¶çš„æ—¶é—´æˆ³

print("\nStarting real-time detection loop... Press 'q' to quit.")

try:
    while True:
        # 1. æ•è·æ‘„åƒå¤´ç”»é¢
        ret, frame_bgr = cap.read()
        if not ret:
            print("Warning: Failed to grab frame from camera. Retrying...")
            continue
        
        original_shape = frame_bgr.shape

        # 2. å›¾åƒé¢„å¤„ç†
        preprocessed_img = preprocess_img(frame_bgr, target_shape=MODEL_INPUT_SHAPE, div_num=255, means=None, stds=None)

        # 3. æ¨¡å‹æ¨ç†
        input_feed = {MODEL_INPUT_NAME: preprocessed_img}
        outputs = snpe_ort.Execute([], input_feed)

        # 4. è¾“å‡ºå¡‘å½¢å’Œåå¤„ç†
        output_data = np.array(outputs[MODEL_OUTPUT_NAME])
        reshaped_output = output_data.reshape(1, 4 + NUM_CLASSES, 8400)
        final_detections = detect_postprocess_yolov8(
            reshaped_output,
            original_shape,
            (MODEL_INPUT_SHAPE[0], MODEL_INPUT_SHAPE[1], 3),
            num_classes=NUM_CLASSES,
            conf_thres=CONF_THRESHOLD,
            iou_thres=IOU_THRESHOLD
        )

        # 5. æ ¸å¿ƒé€»è¾‘ï¼šæ ¹æ®æ£€æµ‹ç»“æœæ›´æ–°çŠ¶æ€å¹¶æ‰§è¡ŒåŠ¨ä½œ
        is_target_detected = len(final_detections[0]) > 0

        if is_target_detected:
            detection_counter += 1
        else:
            detection_counter = 0 # å¦‚æœå½“å‰å¸§æ²¡æœ‰ç›®æ ‡ï¼Œé‡ç½®è®¡æ•°å™¨

        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ‹æ‘„æ¡ä»¶
        is_cooldown_over = (time.time() - last_capture_time) > CAPTURE_COOLDOWN_SECONDS
        is_sustained_detection = detection_counter >= SUSTAINED_DETECTION_FRAMES_THRESHOLD

        if is_sustained_detection and is_cooldown_over and not is_recording:
            # --- è§¦å‘æ‹ç…§å’Œå½•åƒ ---
            timestamp_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # (1) æ‹æ‘„å›¾ç‰‡
            photo_path = os.path.join(SAVE_DIR, f"photo_{timestamp_str}.jpg")
            cv2.imwrite(photo_path, frame_bgr)
            print(f"âœ… Sustained target detected! Photo saved to: {photo_path}")

            # (2) å¼€å§‹10ç§’è§†é¢‘æ‹æ‘„
            video_path = os.path.join(SAVE_DIR, f"video_{timestamp_str}.mp4")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v') # æˆ–è€… 'XVID' for .avi
            video_writer = cv2.VideoWriter(video_path, fourcc, fps, (frame_width, frame_height))
            is_recording = True
            video_start_time = time.time()
            print(f"ğŸ¥ Starting {VIDEO_DURATION_SECONDS}-second video recording to: {video_path}")

            # æ›´æ–°å†·å´è®¡æ—¶å™¨
            last_capture_time = time.time() 
            # é‡ç½®æ£€æµ‹è®¡æ•°å™¨ï¼Œé˜²æ­¢åœ¨æœ¬æ¬¡å½•åƒæœŸé—´å†æ¬¡è§¦å‘
            detection_counter = 0


        # 6. å¤„ç†æ­£åœ¨å½•åˆ¶ä¸­çš„è§†é¢‘
        if is_recording:
            # å°†å½“å‰å¸§ï¼ˆæ— è®ºæ˜¯å¦å¸¦æ¡†ï¼‰å†™å…¥è§†é¢‘æ–‡ä»¶
            video_writer.write(frame_bgr) 
            
            # æ£€æŸ¥å½•åƒæ˜¯å¦è¾¾åˆ°æŒ‡å®šæ—¶é•¿
            if time.time() - video_start_time >= VIDEO_DURATION_SECONDS:
                video_writer.release()
                video_writer = None
                is_recording = False
                print(f"ğŸ¬ Video recording finished. Entering {CAPTURE_COOLDOWN_SECONDS}-second cooldown.")
                # æ³¨æ„ï¼šlast_capture_timeåœ¨å¼€å§‹å½•åˆ¶æ—¶å·²æ›´æ–°ï¼Œæ­¤å¤„æ— éœ€å†æ›´æ–°

        # 7. ç»“æœå¯è§†åŒ–
        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        result_image = draw_detect_res(frame_rgb, final_detections, class_names=CLASS_NAMES)
        result_image_bgr = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)

        # åœ¨ç”»é¢ä¸Šæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        status_text = ""
        if is_recording:
            status_text = f"RECORDING... {int(time.time() - video_start_time)}s"
        elif not is_cooldown_over:
            remaining_cooldown = int(CAPTURE_COOLDOWN_SECONDS - (time.time() - last_capture_time))
            status_text = f"COOLDOWN: {remaining_cooldown}s left"
        else:
             status_text = f"Detecting... ({detection_counter}/{SUSTAINED_DETECTION_FRAMES_THRESHOLD})"
        
        cv2.putText(result_image_bgr, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        cv2.imshow('Real-time YOLOv8 Detection', result_image_bgr)

        # æ£€æµ‹é€€å‡ºé”®
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

finally:
    # 8. é‡Šæ”¾èµ„æº
    print("\nCleaning up and shutting down...")
    if is_recording and video_writer is not None:
        video_writer.release() # ç¡®ä¿ç¨‹åºé€€å‡ºæ—¶ï¼Œæ­£åœ¨å½•åˆ¶çš„è§†é¢‘èƒ½è¢«ä¿å­˜
        print("Saved pending video before exit.")
    cap.release()
    cv2.destroyAllWindows()
    # snpe_ort.Terminate() # å¦‚æœapi_inferåº“æœ‰æä¾›ç»ˆæ­¢æ–¹æ³•ï¼Œè¯·è°ƒç”¨
    print("Cleanup complete. Exiting.")